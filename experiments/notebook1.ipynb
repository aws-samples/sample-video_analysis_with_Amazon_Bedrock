{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26eb8fb4-99bd-4ee5-b410-8fc296f81159",
   "metadata": {},
   "source": [
    "# Nova Video Understanding\n",
    "\n",
    "In this notebook we will be using Amazon Nova Pro's video understanding capability to analyze the video."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73610980-bddc-4585-94e5-f720a700e352",
   "metadata": {},
   "source": [
    "Ensure you have latest version of boto and have bedrock model access for Nova models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d458bcf-5c4a-404f-b51a-e25b59e2cf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install botocore --upgrade\n",
    "!pip install boto3 --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40464e8c-fa3e-4e23-9923-34b503423568",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8855f79-63d4-4714-b426-a8a6458cb487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3 \n",
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket() # Set a default S3 bucket\n",
    "prefix = 'nova_video'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578235aa-fe01-47d5-b1f4-beb55fc9de58",
   "metadata": {},
   "source": [
    "# Experiment 1B - Combined video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e2ed24-a45f-41d3-8209-929c5ffd9b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "\n",
    "bucket = \"<<bucket>>\" # Set a default S3 bucket\n",
    "\n",
    "\n",
    "# AWS Configuration\n",
    "AWS_ACCOUNT = boto3.client('sts').get_caller_identity().get('Account')\n",
    "AWS_REGION = \"us-east-1\"\n",
    "INFERENCE_PROFILE = f\"arn:aws:bedrock:{AWS_REGION}:{AWS_ACCOUNT}:inference-profile/us.amazon.nova-pro-v1:0\"\n",
    "S3_BUCKET = bucket\n",
    "\n",
    "# Video Configuration\n",
    "VIDEO_FILE = \"combined_videos.mov\"\n",
    "s3url = \"s3://<<bucket-name>>nova_video/combined_videos.mov\"\n",
    "\n",
    "def parse_llm_response(json_string):\n",
    "    try:\n",
    "        # Parse the JSON string\n",
    "        data = json.loads(json_string)\n",
    "        \n",
    "        # Extract output content\n",
    "        output_content = []\n",
    "        if \"output\" in data:\n",
    "            if \"message\" in data[\"output\"]:\n",
    "                if \"content\" in data[\"output\"][\"message\"]:\n",
    "                    for content_item in data[\"output\"][\"message\"][\"content\"]:\n",
    "                        if \"text\" in content_item:\n",
    "                            output_content.append(content_item[\"text\"])\n",
    "        \n",
    "        # Extract token information\n",
    "        token_info = {}\n",
    "        if \"usage\" in data:\n",
    "            token_info = {\n",
    "                \"input_tokens\": data[\"usage\"].get(\"inputTokens\", 0),\n",
    "                \"output_tokens\": data[\"usage\"].get(\"outputTokens\", 0),\n",
    "                \"total_tokens\": data[\"usage\"].get(\"totalTokens\", 0)\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            \"content\": output_content,\n",
    "            \"tokens\": token_info\n",
    "        }\n",
    "    except json.JSONDecodeError:\n",
    "        return {\"error\": \"Invalid JSON string\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"An error occurred: {str(e)}\"}\n",
    "\n",
    "# Prompt Configuration\n",
    "system_prompt = \"\"\n",
    "user_prompt = (\"\"\"    As an expert traffic safety analyst, analyze the provided traffic video footage showing 3 simultaneous camera angles (Left, Center, Right views) and:\n",
    "\n",
    "1. Safe Driving Behaviors (analyze across all 3 frames):\n",
    "\n",
    "* Identify and highlight instances of proper following distance maintenance from multiple angles\n",
    "* Note correct use of turn signals and lane changes as visible in different views\n",
    "* Recognize appropriate speed adjustments for conditions with comprehensive perspective\n",
    "* Point out defensive driving techniques visible across camera angles\n",
    "* Correlate behaviors visible across multiple frames for complete assessment\n",
    "\n",
    "2. Driver Safety Practices (focus on interior/center frame):\n",
    "\n",
    "* Detect proper seat belt usage\n",
    "* Observe correct hand positioning on steering wheel\n",
    "* Note appropriate mirror checks during maneuvers\n",
    "* Identify distraction-free driving behaviors. For example not using cellphone or eating\n",
    "* Compare driver actions with external views for context\n",
    "\n",
    "3. Critical Analysis (synthesizing all 3 views):\n",
    "\n",
    "* Timestamp each identified safe driving behavior noting which frame(s) displayed the action\n",
    "* Rate the effectiveness of each observed safety practice (1-5 scale) considering multi-angle visibility\n",
    "* Provide specific commentary on what makes each highlighted action exemplary with reference to relevant camera angles\n",
    "* Note how these actions contributed to accident prevention based on comprehensive view\n",
    "* Highlight instances where multiple camera angles provided better safety assessment\n",
    "\n",
    "4. Multi-View Integration:\n",
    "\n",
    "* Note any safety behaviors that were only visible in specific frames\n",
    "* Identify how different angles complement each other for complete safety analysis\n",
    "* Compare and contrast safety observations between frames\n",
    "* Highlight the value of multiple perspectives in assessing traffic safety\n",
    "\n",
    "Generate driver score and provide recommendation/feedback for improvement\n",
    "\"\"\")\n",
    "\n",
    "# Message Configuration\n",
    "user_message_list = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"video\": {\n",
    "                    \"format\": \"mp4\",\n",
    "                    \"source\": {\n",
    "                        \"s3Location\": {\n",
    "                            \"uri\": s3url,\n",
    "                            \"bucketOwner\": AWS_ACCOUNT\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"text\": user_prompt\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "system_message_list = [\n",
    "    {\n",
    "        \"text\": \"You are an expert traffic safety analyst.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "body = {\n",
    "    \"schemaVersion\": \"messages-v1\",\n",
    "    \"system\": system_message_list,\n",
    "    \"messages\": user_message_list,\n",
    "    \"inferenceConfig\": {\"max_new_tokens\": 1024, \"top_p\": 0.1, \"temperature\": 0.1},\n",
    "}\n",
    "\n",
    "# Invoke Bedrock model\n",
    "try:\n",
    "    bedrock_runtime = boto3.client(\"bedrock-runtime\", region_name=AWS_REGION)\n",
    "    invocation = bedrock_runtime.invoke_model(\n",
    "        body=json.dumps(body),\n",
    "        modelId=INFERENCE_PROFILE,\n",
    "        accept=\"application/json\",\n",
    "        contentType=\"application/json\"\n",
    "    )\n",
    "\n",
    "    # Process response\n",
    "    response_body = invocation[\"body\"].read().decode('utf-8')\n",
    "    print(\"Raw response:\", response_body)\n",
    "    \n",
    "    # Parse the response using our parser\n",
    "    parsed_response = parse_llm_response(response_body)\n",
    "    \n",
    "    # Print formatted results\n",
    "    print(\"\\nParsed Output Content:\")\n",
    "    for content in parsed_response[\"content\"]:\n",
    "        print(content)\n",
    "        print(\"\\n---\\n\")\n",
    "\n",
    "    print(\"Token Information:\")\n",
    "    for key, value in parsed_response[\"tokens\"].items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7b9c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "\n",
    "bucket = \"<<bucket>>\" # Set a default S3 bucket\n",
    "\n",
    "\n",
    "# AWS Configuration\n",
    "AWS_ACCOUNT = boto3.client('sts').get_caller_identity().get('Account')\n",
    "AWS_REGION = \"us-east-1\"\n",
    "INFERENCE_PROFILE = f\"arn:aws:bedrock:{AWS_REGION}:{AWS_ACCOUNT}:inference-profile/us.amazon.nova-pro-v1:0\"\n",
    "S3_BUCKET = bucket\n",
    "\n",
    "# Video Configuration\n",
    "VIDEO_FILE = \"combined_videos.mov\"\n",
    "s3url = \"s3://<<bucket>>/nova_video/combined_videos.mov\"\n",
    "\n",
    "def parse_llm_response(json_string):\n",
    "    try:\n",
    "        # Parse the JSON string\n",
    "        data = json.loads(json_string)\n",
    "        \n",
    "        # Extract output content\n",
    "        output_content = []\n",
    "        if \"output\" in data:\n",
    "            if \"message\" in data[\"output\"]:\n",
    "                if \"content\" in data[\"output\"][\"message\"]:\n",
    "                    for content_item in data[\"output\"][\"message\"][\"content\"]:\n",
    "                        if \"text\" in content_item:\n",
    "                            output_content.append(content_item[\"text\"])\n",
    "        \n",
    "        # Extract token information\n",
    "        token_info = {}\n",
    "        if \"usage\" in data:\n",
    "            token_info = {\n",
    "                \"input_tokens\": data[\"usage\"].get(\"inputTokens\", 0),\n",
    "                \"output_tokens\": data[\"usage\"].get(\"outputTokens\", 0),\n",
    "                \"total_tokens\": data[\"usage\"].get(\"totalTokens\", 0)\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            \"content\": output_content,\n",
    "            \"tokens\": token_info\n",
    "        }\n",
    "    except json.JSONDecodeError:\n",
    "        return {\"error\": \"Invalid JSON string\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"An error occurred: {str(e)}\"}\n",
    "\n",
    "# Prompt Configuration\n",
    "system_prompt = \"\"\n",
    "user_prompt = (\"\"\"    As an expert traffic safety analyst, analyze the provided traffic video footage showing 3 simultaneous camera angles and:\n",
    "\n",
    "Analyze the provided video footage and answer the following:\n",
    "Are there any pedestrians visible? If yes, describe their location, actions, and appearance.\n",
    "Are any pedestrians at risk due to the driver's behavior? Explain why or why not.\n",
    "Is the driver driving safely? Provide specific examples of unsafe or safe behaviors.\n",
    "Is the driver distracted? If so, describe how and when.\n",
    "\"\"\")\n",
    "\n",
    "# Message Configuration\n",
    "user_message_list = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"video\": {\n",
    "                    \"format\": \"mov\",\n",
    "                    \"source\": {\n",
    "                        \"s3Location\": {\n",
    "                            \"uri\": s3url,\n",
    "                            \"bucketOwner\": AWS_ACCOUNT\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"text\": user_prompt\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "system_message_list = [\n",
    "    {\n",
    "        \"text\": \"You are an expert traffic safety analyst.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "body = {\n",
    "    \"schemaVersion\": \"messages-v1\",\n",
    "    \"system\": system_message_list,\n",
    "    \"messages\": user_message_list,\n",
    "    \"inferenceConfig\": {\"max_new_tokens\": 1024, \"top_p\": 0.1, \"temperature\": 0.1},\n",
    "}\n",
    "\n",
    "# Invoke Bedrock model\n",
    "try:\n",
    "    bedrock_runtime = boto3.client(\"bedrock-runtime\", region_name=AWS_REGION)\n",
    "    invocation = bedrock_runtime.invoke_model(\n",
    "        body=json.dumps(body),\n",
    "        modelId=INFERENCE_PROFILE,\n",
    "        accept=\"application/json\",\n",
    "        contentType=\"application/json\"\n",
    "    )\n",
    "\n",
    "    # Process response\n",
    "    response_body = invocation[\"body\"].read().decode('utf-8')\n",
    "    print(\"Raw response:\", response_body)\n",
    "    \n",
    "    # Parse the response using our parser\n",
    "    parsed_response = parse_llm_response(response_body)\n",
    "    \n",
    "    # Print formatted results\n",
    "    print(\"\\nParsed Output Content:\")\n",
    "    for content in parsed_response[\"content\"]:\n",
    "        print(content)\n",
    "        print(\"\\n---\\n\")\n",
    "\n",
    "    print(\"Token Information:\")\n",
    "    for key, value in parsed_response[\"tokens\"].items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ac7dd9-3ee3-4921-8ab9-1844f78833f7",
   "metadata": {},
   "source": [
    "# Option 1 A: Call Nova for each model and then do final summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954c2f6c-a6f6-4ea8-9703-5d9db2f35c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "def analyze_traffic_video(video_url, aws_region=\"us-east-1\", bucket_owner=None):\n",
    "    \"\"\"\n",
    "    Analyzes traffic video for safety behaviors using AWS Bedrock.\n",
    "    \n",
    "    Args:\n",
    "        video_url (str): S3 URL of the video to analyze\n",
    "        aws_region (str): AWS region (default: \"us-east-1\")\n",
    "        bucket_owner (str): AWS account ID of bucket owner (optional)\n",
    "        \n",
    "    Returns:\n",
    "        dict: Parsed response containing analysis results and token information\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get AWS account ID if not provided\n",
    "        if not bucket_owner:\n",
    "            bucket_owner = boto3.client('sts').get_caller_identity().get('Account')\n",
    "            \n",
    "        # Configure inference profile\n",
    "        inference_profile = f\"arn:aws:bedrock:{aws_region}:{bucket_owner}:inference-profile/us.amazon.nova-pro-v1:0\"\n",
    "        \n",
    "        # Define prompts\n",
    "        user_prompt = \"\"\"As an expert traffic safety analyst, analyze the provided traffic video footage showing 3 simultaneous camera angles (Left, Center, Right views) and:\n",
    "\n",
    "1. Safe Driving Behaviors (analyze across all 3 frames):\n",
    "* Identify and highlight instances of proper following distance maintenance from multiple angles\n",
    "* Note correct use of turn signals and lane changes as visible in different views\n",
    "* Recognize appropriate speed adjustments for conditions with comprehensive perspective\n",
    "* Point out defensive driving techniques visible across camera angles\n",
    "* Correlate behaviors visible across multiple frames for complete assessment\n",
    "\n",
    "2. Driver Safety Practices (focus on interior/center frame):\n",
    "* Detect proper seat belt usage\n",
    "* Observe correct hand positioning on steering wheel\n",
    "* Note appropriate mirror checks during maneuvers\n",
    "* Identify distraction-free driving behaviors\n",
    "* Compare driver actions with external views for context\n",
    "\n",
    "3. Critical Analysis (synthesizing all 3 views):\n",
    "* Timestamp each identified safe driving behavior noting which frame(s) displayed the action\n",
    "* Rate the effectiveness of each observed safety practice (1-5 scale)\n",
    "* Provide specific commentary on what makes each highlighted action exemplary\n",
    "* Note how these actions contributed to accident prevention\n",
    "* Highlight instances where multiple camera angles provided better safety assessment\n",
    "\n",
    "4. Multi-View Integration:\n",
    "* Note any safety behaviors that were only visible in specific frames\n",
    "* Identify how different angles complement each other\n",
    "* Compare and contrast safety observations between frames\n",
    "* Highlight the value of multiple perspectives\n",
    "\n",
    "Generate driver score and provide recommendation/feedback for improvement\"\"\"\n",
    "\n",
    "        # Configure messages\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"video\": {\n",
    "                            \"format\": \"mp4\",\n",
    "                            \"source\": {\n",
    "                                \"s3Location\": {\n",
    "                                    \"uri\": video_url,\n",
    "                                    \"bucketOwner\": bucket_owner\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        \"text\": user_prompt\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        system_messages = [\n",
    "            {\n",
    "                \"text\": \"You are an expert traffic safety analyst.\"\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        # Prepare request body\n",
    "        request_body = {\n",
    "            \"schemaVersion\": \"messages-v1\",\n",
    "            \"system\": system_messages,\n",
    "            \"messages\": messages,\n",
    "            \"inferenceConfig\": {\n",
    "                \"max_new_tokens\": 1024,\n",
    "                \"top_p\": 0.1,\n",
    "                \"temperature\": 0.1\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Initialize Bedrock client and invoke model\n",
    "        bedrock_runtime = boto3.client(\"bedrock-runtime\", region_name=aws_region)\n",
    "        response = bedrock_runtime.invoke_model(\n",
    "            body=json.dumps(request_body),\n",
    "            modelId=inference_profile,\n",
    "            accept=\"application/json\",\n",
    "            contentType=\"application/json\"\n",
    "        )\n",
    "\n",
    "        # Parse and process response\n",
    "        response_body = response[\"body\"].read().decode('utf-8')\n",
    "        return parse_llm_response(response_body)\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Analysis failed: {str(e)}\"}\n",
    "\n",
    "def parse_llm_response(json_string):\n",
    "    \"\"\"\n",
    "    Parses the LLM response JSON string.\n",
    "    \n",
    "    Args:\n",
    "        json_string (str): JSON response from the model\n",
    "        \n",
    "    Returns:\n",
    "        dict: Parsed content and token information\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = json.loads(json_string)\n",
    "        \n",
    "        output_content = []\n",
    "        if \"output\" in data:\n",
    "            if \"message\" in data[\"output\"]:\n",
    "                if \"content\" in data[\"output\"][\"message\"]:\n",
    "                    for content_item in data[\"output\"][\"message\"][\"content\"]:\n",
    "                        if \"text\" in content_item:\n",
    "                            output_content.append(content_item[\"text\"])\n",
    "        \n",
    "        token_info = {}\n",
    "        if \"usage\" in data:\n",
    "            token_info = {\n",
    "                \"input_tokens\": data[\"usage\"].get(\"inputTokens\", 0),\n",
    "                \"output_tokens\": data[\"usage\"].get(\"outputTokens\", 0),\n",
    "                \"total_tokens\": data[\"usage\"].get(\"totalTokens\", 0)\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            \"content\": output_content,\n",
    "            \"tokens\": token_info\n",
    "        }\n",
    "    except json.JSONDecodeError:\n",
    "        return {\"error\": \"Invalid JSON response\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Parsing error: {str(e)}\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5c1d6e-946f-417f-ad42-b9aa6b7b9d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_analysis_output(response_dict):\n",
    "    \"\"\"\n",
    "    Formats the analysis output into a readable structure\n",
    "    \n",
    "    Args:\n",
    "        response_dict (dict): The response dictionary containing content and tokens\n",
    "        \n",
    "    Returns:\n",
    "        str: Formatted analysis text\n",
    "    \"\"\"\n",
    "    if 'content' not in response_dict or not response_dict['content']:\n",
    "        return \"No content available\"\n",
    "\n",
    "    # Get the analysis text from the content\n",
    "    analysis_text = response_dict['content'][0]\n",
    "    \n",
    "    # Split the text into sections\n",
    "    sections = analysis_text.split('\\n\\n')\n",
    "    \n",
    "    # Format the output\n",
    "    formatted_output = \"\"\"\n",
    "TRAFFIC VIDEO ANALYSIS REPORT\n",
    "============================\n",
    "\n",
    "\"\"\"\n",
    "    for section in sections:\n",
    "        if section.startswith('1. Safe'):\n",
    "            formatted_output += \"SAFE DRIVING BEHAVIORS\\n\" + \"=\"*20 + \"\\n\"\n",
    "            behaviors = section.split('- ')[1:]\n",
    "            for behavior in behaviors:\n",
    "                formatted_output += f\"• {behavior}\\n\"\n",
    "                \n",
    "        elif section.startswith('2. Driver'):\n",
    "            formatted_output += \"\\nDRIVER SAFETY PRACTICES\\n\" + \"=\"*20 + \"\\n\"\n",
    "            practices = section.split('- ')[1:]\n",
    "            for practice in practices:\n",
    "                formatted_output += f\"• {practice}\\n\"\n",
    "                \n",
    "        elif section.startswith('3. Critical'):\n",
    "            formatted_output += \"\\nCRITICAL ANALYSIS\\n\" + \"=\"*20 + \"\\n\"\n",
    "            analyses = section.split('- ')[1:]\n",
    "            for analysis in analyses:\n",
    "                formatted_output += f\"• {analysis}\\n\"\n",
    "                \n",
    "        elif section.startswith('4. Multi'):\n",
    "            formatted_output += \"\\nMULTI-VIEW INTEGRATION\\n\" + \"=\"*20 + \"\\n\"\n",
    "            points = section.split('- ')[1:]\n",
    "            for point in points:\n",
    "                formatted_output += f\"• {point}\\n\"\n",
    "                \n",
    "        elif section.startswith('Driver score'):\n",
    "            formatted_output += \"\\nFINAL ASSESSMENT\\n\" + \"=\"*20 + \"\\n\"\n",
    "            scores = section.split('\\n')\n",
    "            for score in scores:\n",
    "                formatted_output += f\"{score}\\n\"\n",
    "\n",
    "    # Add token information\n",
    "    if 'tokens' in response_dict:\n",
    "        formatted_output += f\"\\nTOKEN USAGE\\n\" + \"=\"*20 + \"\\n\"\n",
    "        for key, value in response_dict['tokens'].items():\n",
    "            formatted_output += f\"{key.replace('_', ' ').title()}: {value}\\n\"\n",
    "\n",
    "    return formatted_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dc03ac-cd0f-4f6d-b7f4-808a4a5e7ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "infacing=analyze_traffic_video(\"s3://<<bucket>>/nova_video/infacing_dc.mov\")\n",
    "infacingresponse=infacing['content'][0]\n",
    "print(infacingresponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dced606d-1ae1-41fb-8488-a5ada9b57697",
   "metadata": {},
   "outputs": [],
   "source": [
    "frontfacing=analyze_traffic_video(\"s3://<<bucket>>/nova_video/frontfacing_dc.mov\")\n",
    "print(frontfacing)\n",
    "frontfacingresponse=frontfacing['content'][0]\n",
    "print(frontfacingresponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6d89b3-5361-4cb7-a89e-63ad18b2924f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sidefacing=analyze_traffic_video(\"s3://<<bucket>>/nova_video/sidefacing_dc.mov\")\n",
    "print(sidefacing)\n",
    "sidefacingresponse=sidefacing['content'][0]\n",
    "print(sidefacingresponse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d1af01-e761-4dd1-a242-c4663cb763f6",
   "metadata": {},
   "source": [
    "# Option 1C - Process individual videos with Amazon Nova Pro and then summarize with Claude Sonnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9c6de0-5c7a-4ac2-af6f-7454f23d3b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "bedrock_client = boto3.client('bedrock-runtime')\n",
    "model_id_sonnet37 =\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\"\n",
    "def summarize(client, inface,side,front,model_id,max_tokens=4096, temperature=0, top_p=0.9):\n",
    "    prompt=\"\"\" You are safety expert for safe driving. Analyze the summary from individual camera feed and \n",
    "    generate the final recommendation and summary \n",
    "    <inward_facing_camera>\"\"\"+inface+ \"\"\"</inward_facing_camera> <side_camera>\"\"\"+side+\"\"\" </side_camera> <front_camera>\"\"\"+front+\"\"\"</front_camera>\"\"\"\n",
    "    \n",
    "    response = \"\"\n",
    "    try:\n",
    "        response = bedrock_client.converse(\n",
    "            modelId=model_id_sonnet37,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"text\": prompt\n",
    "                        } \n",
    "                    ]\n",
    "                }\n",
    "                    \n",
    "            ],\n",
    "            inferenceConfig={\n",
    "                \"temperature\": temperature,\n",
    "                \"maxTokens\": max_tokens,\n",
    "                \"topP\": top_p\n",
    "            }\n",
    "            #additionalModelRequestFields={\n",
    "            #}\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        result = \"Model invocation error\"\n",
    "    try:\n",
    "        res=response['output']['message']['content'][0]['text']\n",
    "        result = response['output']['message']['content'][0]['text'] \\\n",
    "        + '\\n--- Latency: ' + str(response['metrics']['latencyMs']) \\\n",
    "        + 'ms - Input tokens:' + str(response['usage']['inputTokens']) \\\n",
    "        + ' - Output tokens:' + str(response['usage']['outputTokens']) + ' ---\\n'\n",
    "        #data=res.split(\":\", 1)\n",
    "        #data.to_csv('file1.csv')\n",
    "        return res\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        result = \"Output parsing error\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d132d7e-fc6a-458d-8f86-03fb46b62f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary=summarize(bedrock_client,infacingresponse,sidefacingresponse,frontfacingresponse,model_id_sonnet37)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02232d6e-4be6-4230-b5e5-465386905ac9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
