{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ad9e44a-86ec-45bd-91a3-5cdf190a5d34",
   "metadata": {},
   "source": [
    "# Video Content analysis using Amazon Bedrock - Claude models\n",
    "In this notebook, we will be performing video content analysis using Amazon Bedrock. We will be leveraging prompt engineering techniques to output a json file which will output the following json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85130eb4-037e-4b30-ab4d-fe49becd84f0",
   "metadata": {},
   "source": [
    "# Install and import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf997f81-abf8-4029-a0f2-d62d7e87c364",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#ffmpeg download \n",
    "#!sudo yum update -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b8cc46-a468-431b-9e31-bfc5149d7e0d",
   "metadata": {},
   "source": [
    "Install ffmpeg using instructions from https://www.maskaravivek.com/post/how-to-install-ffmpeg-on-ec2-running-amazon-linux/\n",
    "Using existing build for Amazon Linux AMI under GNU license - https://www.johnvansickle.com/ffmpeg/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a1eec0-31f5-43a3-9a2d-8b9aacaf298b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install webvtt-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e108a603-3a43-422f-ac51-4ebbb5548fa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install PhotoHash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbeed10-1831-4b41-822a-1a178a022b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c813b62-1192-427e-aecb-94732d79a976",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install ffmpeg=*=lgpl*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5983e77-42d7-429b-bbbf-95b7a0c2de0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbda465-4344-4d7a-9853-a3a8c8785b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install m3u8-To-MP4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e62401-7de6-4fab-8079-6514eb4dc618",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import sagemaker and aws utils\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "#import helper modules\n",
    "import sys\n",
    "import subprocess \n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "import time\n",
    "import webvtt\n",
    "import re\n",
    "import fsspec\n",
    "import random\n",
    "from pathlib import Path\n",
    "from urllib.parse import urlparse\n",
    "from IPython.display import HTML, display, Image as IImage\n",
    "from PIL import Image, ImageDraw, ImageFont, ExifTags, ImageColor\n",
    "import io\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import base64\n",
    "import pprint\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "import photohash\n",
    "import shutil\n",
    "import tempfile\n",
    "import time\n",
    "import json \n",
    "import sagemaker\n",
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "#lmm, orchestration, vector store\n",
    "# from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth, helpers\n",
    "# from langchain.vectorstores import OpenSearchVectorSearch\n",
    "# from langchain.embeddings import BedrockEmbeddings\n",
    "\n",
    "# from langchain.document_loaders.csv_loader import CSVLoader\n",
    "# from langchain.document_loaders import S3FileLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0462ba61-9955-4d87-8b55-931bda35e600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "\n",
    "s3_client=boto3.client('s3')\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ef96bd-26f7-4630-9c39-df4d489cacf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#credentials and clients\n",
    "aws_account_id  = boto3.client('sts').get_caller_identity()['Account']  \n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "print(sess)\n",
    "print(role)\n",
    "\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "print(region)\n",
    "\n",
    "credentials = boto3.Session().get_credentials().get_frozen_credentials()\n",
    "access_key = credentials.access_key\n",
    "secret_key = credentials.secret_key\n",
    "\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "bedrock_client = boto3.client(service_name='bedrock-runtime', \n",
    "                              region_name=region)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc2d2d7-5a6d-4d12-b81d-87fac64c7428",
   "metadata": {},
   "source": [
    "# Generate summary and results functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25225cdd-cbed-4245-a788-fb35188623c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id_haiku = \"us.anthropic.claude-3-5-haiku-20241022-v1:0\" \n",
    "model_id_sonnet35v2 =\"us.anthropic.claude-3-5-sonnet-20241022-v2:0\"\n",
    "model_id_sonnet37 =\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de05705-db77-450a-a02d-44384f49788a",
   "metadata": {},
   "source": [
    "## Prepare Video Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfd0a7a-a949-48ca-a603-d4b835cc26ba",
   "metadata": {},
   "source": [
    "Get frame images for each video and store as a grid of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008952d9-024f-40aa-902a-452e91e31bdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_frames(video_path,key):\n",
    "    # Set the S3 bucket and folder paths\n",
    "    print(\"video-path\",video_path)\n",
    "    video_filename = key.split('/')[-1]\n",
    "    # Construct the S3 key for the input video file\n",
    "    #s3_key = f\"{video_path}/{video_filename}\"\n",
    "    print(\"video file---\", video_filename)\n",
    "\n",
    "    # Create a temporary directory\n",
    "    output_dir = Path(f\"/tmp/{random.randint(0, 1000000)}\")\n",
    "    while output_dir.exists():\n",
    "        output_dir = Path(f\"/tmp/{random.randint(0, 1000000)}\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=False)\n",
    "\n",
    "    # Download the video file from S3\n",
    "    local_video_path = f\"/tmp/{video_filename}\"\n",
    "    print(\"local_video_path---\", local_video_path)\n",
    "    print(\"bucket---\", bucket)\n",
    "    s3_client = boto3.client('s3')\n",
    "    s3_client.download_file(bucket, key, local_video_path)\n",
    "\n",
    "    # Set the output pattern for extracted frames\n",
    "    output_pattern = output_dir / \"frame-%07d.jpg\"\n",
    "    print(output_pattern)\n",
    "\n",
    "    # Construct the ffmpeg command\n",
    "    frame_rate = 1/1 ## extract second for each second\n",
    "    ffmpeg_cmd = [\"ffmpeg\", \"-i\", local_video_path, \"-vf\", f\"fps={frame_rate}\", str(output_pattern)]\n",
    "\n",
    "    try:\n",
    "        subprocess.run(ffmpeg_cmd, check=True)\n",
    "    except subprocess.CalledProcessError as err:\n",
    "        print(f\"Error running ffmpeg: {err}\")\n",
    "\n",
    "    # Clean up the temporary video file\n",
    "    os.remove(local_video_path)\n",
    "\n",
    "    # Upload the extracted frames to S3\n",
    "    for frame_file in output_dir.glob(\"*.jpg\"):\n",
    "        s3_output_key = f\"{frame_images_path}/{video_filename}/{frame_file.name}\"\n",
    "        #print (\"Uploading file to:\"+s3_output_key)\n",
    "        s3_client.upload_file(str(frame_file), bucket, s3_output_key)\n",
    "\n",
    "    # Clean up the temporary directory\n",
    "    for file in output_dir.glob(\"*\"):\n",
    "        file.unlink()\n",
    "    output_dir.rmdir()\n",
    "\n",
    "    return f\"s3://{bucket}/{frame_images_path}/{video_filename}/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4083b0e-2148-4971-a8c6-e29a21173002",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###Creates a 4x4 grid layout of sequential frames from video/animation\n",
    "###Adds frame numbers on black bars above each image\n",
    "###Saves multiple grid images if there are more than 16 frames\n",
    "\n",
    "def create_tiled_image(s3_path, font_type):\n",
    "    # Parse the S3 path\n",
    "    parsed_url = urlparse(s3_path)\n",
    "    bucket_name = parsed_url.netloc\n",
    "    folder_path = parsed_url.path.lstrip('/')\n",
    "    print (\"folder path:\"+folder_path)\n",
    "\n",
    "    s3 = boto3.resource('s3')\n",
    "\n",
    "    bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "    # Get the list of image files in the S3 folder\n",
    "    image_keys = [obj.key for obj in bucket.objects.filter(Prefix=folder_path)]\n",
    "    selected_keys = []\n",
    "    for key in image_keys:\n",
    "        if key.endswith(\".jpg\") and \"computed\" not in key:\n",
    "            selected_keys.append(key)\n",
    "    \n",
    "    # Sort the image files by frame number\n",
    "    selected_keys.sort(key=lambda x: int(x.split('-')[-1].split('.')[0]))\n",
    "\n",
    "    # Select all frames and generate multiple images\n",
    "\n",
    "    num_frames = len(selected_keys)\n",
    "\n",
    "    # Load the selected images from S3\n",
    "    images = []\n",
    "    for key in selected_keys:\n",
    "        image_obj = bucket.Object(key).get()\n",
    "        image_data = image_obj['Body'].read()\n",
    "        image = Image.open(BytesIO(image_data))\n",
    "        images.append(image)\n",
    "\n",
    "    # Create a new image to hold the 4x4 tiled grid\n",
    "    tile_width = images[0].width * 4\n",
    "    tile_height = images[0].height * 4 + 50  # Extra height for the black bar\n",
    "    tiled_image = Image.new('RGB', (tile_width, tile_height))\n",
    "\n",
    "    # Draw the images onto the tiled grid with a black bar on top\n",
    "    num_images = num_frames / 16\n",
    "    #print(\"number of image grids: \"+str(num_images))\n",
    "    print(\"number of frames: \"+str(num_frames))\n",
    "    num_images_int = int(num_images)\n",
    "    if num_images > num_images_int:\n",
    "        num_images_int = num_images_int + 1\n",
    "    print(\"number of image grids: \"+str(num_images_int))\n",
    "    frame_counter = 0\n",
    "    for k in range(num_images_int):\n",
    "        for i in range(16):\n",
    "            if frame_counter < num_frames and images[frame_counter]:\n",
    "                row = i // 4\n",
    "                col = i % 4\n",
    "                x = col * images[frame_counter].width\n",
    "                y = row * images[frame_counter].height + 50  # Offset for the black bar\n",
    "                tiled_image.paste(images[frame_counter], (x, y))\n",
    "                #print(\"frame counter:\"+str(frame_counter))\n",
    "\n",
    "                # Draw a black bar on top of the image\n",
    "                draw = ImageDraw.Draw(tiled_image)\n",
    "                bar_x = col * images[frame_counter].width\n",
    "                bar_y = row * images[frame_counter].height\n",
    "                bar_width = images[frame_counter].width\n",
    "                bar_height = 50  # Increased height for the black bar\n",
    "                draw.rectangle([(bar_x, bar_y), (bar_x + bar_width, bar_y + bar_height)], fill=(0, 0, 0))\n",
    "\n",
    "                # Add frame number in white color on the black bar\n",
    "                font_size = 50  # Increased font size\n",
    "                frame_number = selected_keys[frame_counter].split('-')[-1].split('.')[0]\n",
    "                text_x = bar_x + 10\n",
    "                text_y = bar_y + 20  # Adjusted y-coordinate for larger font\n",
    "                font = ImageFont.truetype(font_type, font_size)\n",
    "                draw.text((text_x, text_y), frame_number, font=font, fill=(255, 255, 255))\n",
    "                \n",
    "                frame_counter = frame_counter + 1\n",
    "\n",
    "        # Save the tiled image to S3\n",
    "        base_filename = Path(folder_path).stem\n",
    "        grid_filename = f'image_grid-{k}-{base_filename}.jpg'\n",
    "        grid_key = f'{folder_path}computed/{grid_filename}'\n",
    "        grid_path = f'{folder_path}computed'\n",
    "        temp_file = BytesIO()\n",
    "        tiled_image.save(temp_file, format='JPEG')\n",
    "        temp_file.seek(0)\n",
    "        bucket.put_object(Key=grid_key, Body=temp_file)\n",
    "    \n",
    "\n",
    "    \n",
    "    return f's3://{bucket_name}/{grid_path}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006507df-f72e-4da4-b2dc-ad95999a0cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tiled_image(s3_path, font_type):\n",
    "    # Parse the S3 path\n",
    "    parsed_url = urlparse(s3_path)\n",
    "    bucket_name = parsed_url.netloc\n",
    "    folder_path = parsed_url.path.lstrip('/')\n",
    "    print(\"folder path:\" + folder_path)\n",
    "\n",
    "    s3 = boto3.resource('s3')\n",
    "    bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "    # Get the list of image files in the S3 folder\n",
    "    image_keys = [obj.key for obj in bucket.objects.filter(Prefix=folder_path)]\n",
    "    selected_keys = []\n",
    "    for key in image_keys:\n",
    "        if key.endswith(\".jpg\") and \"computed\" not in key:\n",
    "            selected_keys.append(key)\n",
    "    \n",
    "    # Sort the image files by frame number\n",
    "    selected_keys.sort(key=lambda x: int(x.split('-')[-1].split('.')[0]))\n",
    "\n",
    "    num_frames = len(selected_keys)\n",
    "    if num_frames == 0:\n",
    "        print(\"No frames found\")\n",
    "        return None\n",
    "\n",
    "    # Load the selected images from S3\n",
    "    images = []\n",
    "    for key in selected_keys:\n",
    "        image_obj = bucket.Object(key).get()\n",
    "        image_data = image_obj['Body'].read()\n",
    "        image = Image.open(BytesIO(image_data))\n",
    "        images.append(image)\n",
    "\n",
    "    # Create a new image to hold the 4x4 tiled grid\n",
    "    tile_width = images[0].width * 4\n",
    "    tile_height = images[0].height * 4 + 50  # Extra height for the black bar\n",
    "    \n",
    "    # Calculate number of complete grids needed\n",
    "    num_images = (num_frames + 15) // 16  # Round up division\n",
    "    print(\"number of frames: \" + str(num_frames))\n",
    "    print(\"number of image grids: \" + str(num_images))\n",
    "\n",
    "    frame_counter = 0\n",
    "    for k in range(num_images):\n",
    "        # Create a new tiled image for each grid\n",
    "        tiled_image = Image.new('RGB', (tile_width, tile_height))\n",
    "        \n",
    "        for i in range(16):\n",
    "            if frame_counter < num_frames:  # Check if we still have frames to process\n",
    "                row = i // 4\n",
    "                col = i % 4\n",
    "                x = col * images[0].width\n",
    "                y = row * images[0].height + 50  # Offset for the black bar\n",
    "                tiled_image.paste(images[frame_counter], (x, y))\n",
    "\n",
    "                # Draw a black bar on top of the image\n",
    "                draw = ImageDraw.Draw(tiled_image)\n",
    "                bar_x = col * images[0].width\n",
    "                bar_y = row * images[0].height\n",
    "                bar_width = images[0].width\n",
    "                bar_height = 50\n",
    "                draw.rectangle([(bar_x, bar_y), (bar_x + bar_width, bar_y + bar_height)], fill=(0, 0, 0))\n",
    "\n",
    "                # Add frame number in white color on the black bar\n",
    "                font_size = 50\n",
    "                frame_number = selected_keys[frame_counter].split('-')[-1].split('.')[0]\n",
    "                text_x = bar_x + 10\n",
    "                text_y = bar_y + 20\n",
    "                font = ImageFont.truetype(font_type, font_size)\n",
    "                draw.text((text_x, text_y), frame_number, font=font, fill=(255, 255, 255))\n",
    "                \n",
    "                frame_counter += 1\n",
    "\n",
    "        # Save the tiled image to S3\n",
    "        base_filename = Path(folder_path).stem\n",
    "        grid_filename = f'image_grid-{k}-{base_filename}.jpg'\n",
    "        grid_key = f'{folder_path}computed/{grid_filename}'\n",
    "        grid_path = f'{folder_path}computed'\n",
    "        temp_file = BytesIO()\n",
    "        tiled_image.save(temp_file, format='JPEG')\n",
    "        temp_file.seek(0)\n",
    "        bucket.put_object(Key=grid_key, Body=temp_file)\n",
    "\n",
    "    return f's3://{bucket_name}/{grid_path}/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b242772a-acfc-4a33-9aff-73e45280fc34",
   "metadata": {},
   "source": [
    "## Multimodal Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0d0a94-5db6-4eda-bc5f-3e5cc57aa72d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_contextual_summary(image_grid_path, modelid):\n",
    "    \"\"\"\n",
    "    Invokes Bedrock's conversation API to run a multimodal inference using the input\n",
    "    provided in the request body.\n",
    "    \n",
    "    Args:\n",
    "        image_grid_path: The Amazon S3 uri for the video's image grid (jpeg)\n",
    "        modelid: The Bedrock model ID to use\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize S3 clients\n",
    "    s3 = boto3.resource('s3')\n",
    "    s3_client = boto3.client('s3')\n",
    "    \n",
    "    # Parse S3 path\n",
    "    bucket_name = image_grid_path.split('/')[2]\n",
    "    prefix = '/'.join(image_grid_path.split('/')[3:])\n",
    "    \n",
    "    logger.info(f\"Bucket name: {bucket_name}\")\n",
    "    logger.info(f\"Prefix: {prefix}\")\n",
    "    \n",
    "    # Get bucket\n",
    "    bucket = s3.Bucket(bucket_name)\n",
    "    \n",
    "    # List objects in the folder\n",
    "    try:\n",
    "        image_objects = list(bucket.objects.filter(Prefix=prefix))\n",
    "        logger.info(f\"Found {len(image_objects)} objects with prefix {prefix}\")\n",
    "        \n",
    "        # Filter for image files (assuming jpeg/jpg)\n",
    "        image_keys = [obj.key for obj in image_objects \n",
    "                     if obj.key.lower().endswith(('.jpg', '.jpeg'))]\n",
    "        logger.info(f\"Found {len(image_keys)} image files\")\n",
    "        \n",
    "        if not image_keys:\n",
    "            logger.warning(f\"No image files found in {image_grid_path}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error listing objects in bucket: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "    # Define the analysis prompt\n",
    "    prompt = \"\"\"\n",
    "    As an expert traffic safety analyst, analyze the provided traffic video footage image grid frames and:\n",
    "\n",
    "    1. Safe Driving Behaviors:\n",
    "    - Identify and highlight instances of proper following distance maintenance\n",
    "    - Note correct use of turn signals and lane changes\n",
    "    - Recognize appropriate speed adjustments for conditions\n",
    "    - Point out defensive driving techniques in action\n",
    "\n",
    "    2. Driver Safety Practices:\n",
    "    - Detect proper seat belt usage\n",
    "    - Observe correct hand positioning on steering wheel\n",
    "    - Note appropriate mirror checks during maneuvers\n",
    "    - Identify distraction-free driving behaviors\n",
    "\n",
    "    3. Critical Analysis:\n",
    "    - Timestamp each identified safe driving behavior\n",
    "    - Rate the effectiveness of each observed safety practice (1-5 scale)\n",
    "    - Provide specific commentary on what makes each highlighted action exemplary\n",
    "    - Note how these actions contributed to accident prevention\n",
    "    \"\"\"\n",
    "\n",
    "    # Construct the input message\n",
    "    message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": prompt}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Process and add images\n",
    "    if image_keys:\n",
    "        for image_key in image_keys:\n",
    "            try:\n",
    "                logger.info(f\"Processing image: {image_key}\")\n",
    "                \n",
    "                # Get image from S3\n",
    "                response = s3_client.get_object(Bucket=bucket_name, Key=image_key)\n",
    "                image_binary = response['Body'].read()\n",
    "                \n",
    "                # Check image size\n",
    "                image_size = len(image_binary)\n",
    "                logger.info(f\"Image size: {image_size} bytes\")\n",
    "                \n",
    "                # Encode image\n",
    "                base64_string = base64.b64encode(image_binary).decode('utf-8')\n",
    "                logger.info(f\"Successfully encoded image {image_key}\")\n",
    "                \n",
    "                # Add to message\n",
    "                message[\"content\"].append({\n",
    "                    \"type\": \"image\",\n",
    "                    \"source\": {\n",
    "                        \"type\": \"base64\",\n",
    "                        \"media_type\": \"image/jpeg\",\n",
    "                        \"data\": base64_string\n",
    "                    }\n",
    "                })\n",
    "                logger.info(f\"Added image {image_key} to message\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing image {image_key}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "    # Verify images were added\n",
    "    image_count = sum(1 for content in message[\"content\"] if content[\"type\"] == \"image\")\n",
    "    logger.info(f\"Total images added to message: {image_count}\")\n",
    "\n",
    "    # Prepare request body\n",
    "    request_body = {\n",
    "        \"messages\": [message],\n",
    "        \"max_tokens\": 2048,\n",
    "        \"temperature\": 0,\n",
    "        \"top_p\": 0.999,\n",
    "        \"top_k\": 250,\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Initialize Bedrock runtime client\n",
    "        bedrock_runtime = boto3.client('bedrock-runtime')\n",
    "        \n",
    "        logger.info(\"Invoking Bedrock model...\")\n",
    "        \n",
    "        # Invoke model\n",
    "        response = bedrock_runtime.invoke_model(\n",
    "            modelId=modelid,\n",
    "            contentType=\"application/json\",\n",
    "            accept=\"application/json\",\n",
    "            body=json.dumps(request_body)\n",
    "        )\n",
    "        \n",
    "        # Process response\n",
    "        response_body = json.loads(response['body'].read())\n",
    "        input_tokens = response_body[\"usage\"][\"input_tokens\"]\n",
    "        output_tokens = response_body[\"usage\"][\"output_tokens\"]\n",
    "        \n",
    "        logger.info(\"\\nInvocation details:\")\n",
    "        logger.info(f\"Input tokens: {input_tokens}\")\n",
    "        logger.info(f\"Output tokens: {output_tokens}\")\n",
    "        \n",
    "        response_content = response_body.get(\"content\", [])\n",
    "        logger.info(f\"\\nModel responses ({len(response_content)}):\")\n",
    "        for content in response_content:\n",
    "            logger.info(content[\"text\"])\n",
    "            \n",
    "        return response_body\n",
    "\n",
    "    except ClientError as error:\n",
    "        logger.error(\n",
    "            \"Failed to invoke model. Error: %s: %s\",\n",
    "            error.response[\"Error\"][\"Code\"],\n",
    "            error.response[\"Error\"][\"Message\"]\n",
    "        )\n",
    "        raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db595ab-4010-4460-bcdc-44d4c998cfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(video_path, key):\n",
    "    try:\n",
    "        print(\"video-path\", video_path)\n",
    "        video_filename = key.split('/')[-1]\n",
    "        print(\"video file---\", video_filename)\n",
    "\n",
    "        # Create a temporary directory\n",
    "        output_dir = Path(f\"/tmp/{random.randint(0, 1000000)}\")\n",
    "        while output_dir.exists():\n",
    "            output_dir = Path(f\"/tmp/{random.randint(0, 1000000)}\")\n",
    "        output_dir.mkdir(parents=True, exist_ok=False)\n",
    "\n",
    "        # Download the video file from S3\n",
    "        local_video_path = f\"/tmp/{video_filename}\"\n",
    "        print(\"local_video_path---\", local_video_path)\n",
    "        print(\"bucket---\", bucket)\n",
    "        \n",
    "        # Check if video exists in S3\n",
    "        s3_client = boto3.client('s3')\n",
    "        try:\n",
    "            # Get video file size\n",
    "            response = s3_client.head_object(Bucket=bucket, Key=key)\n",
    "            file_size = response['ContentLength']\n",
    "            print(f\"Video file size: {file_size} bytes\")\n",
    "\n",
    "            if file_size == 0:\n",
    "                print(\"Error: Video file is empty\")\n",
    "                return None\n",
    "\n",
    "            # Download with progress\n",
    "            print(\"Downloading video file...\")\n",
    "            s3_client.download_file(bucket, key, local_video_path)\n",
    "\n",
    "            # Verify the downloaded file\n",
    "            if not os.path.exists(local_video_path):\n",
    "                print(\"Error: Failed to download video file\")\n",
    "                return None\n",
    "\n",
    "            local_size = os.path.getsize(local_video_path)\n",
    "            if local_size != file_size:\n",
    "                print(f\"Error: Downloaded file size ({local_size}) doesn't match S3 file size ({file_size})\")\n",
    "                return None\n",
    "\n",
    "            # Check video file integrity using ffprobe\n",
    "            probe_cmd = [\"ffprobe\", \"-v\", \"error\", local_video_path]\n",
    "            result = subprocess.run(probe_cmd, capture_output=True, text=True)\n",
    "            if result.returncode != 0:\n",
    "                print(f\"Error: Video file is corrupted: {result.stderr}\")\n",
    "                return None\n",
    "\n",
    "            # Set the output pattern for extracted frames\n",
    "            output_pattern = output_dir / \"frame-%07d.jpg\"\n",
    "            print(f\"Output pattern: {output_pattern}\")\n",
    "\n",
    "            # Construct the ffmpeg command with more detailed options\n",
    "            frame_rate = 1/1\n",
    "            ffmpeg_cmd = [\n",
    "                \"ffmpeg\",\n",
    "                \"-v\", \"error\",  # Only show errors\n",
    "                \"-i\", local_video_path,\n",
    "                \"-vf\", f\"fps={frame_rate}\",\n",
    "                \"-frame_pts\", \"1\",  # Add presentation timestamp\n",
    "                \"-q:v\", \"2\",  # High quality\n",
    "                str(output_pattern)\n",
    "            ]\n",
    "\n",
    "            print(\"Executing ffmpeg command:\", \" \".join(ffmpeg_cmd))\n",
    "            result = subprocess.run(ffmpeg_cmd, capture_output=True, text=True)\n",
    "            \n",
    "            if result.returncode != 0:\n",
    "                print(f\"Error running ffmpeg: {result.stderr}\")\n",
    "                return None\n",
    "\n",
    "            # Check if any frames were extracted\n",
    "            frames = list(output_dir.glob(\"*.jpg\"))\n",
    "            if not frames:\n",
    "                print(\"No frames were extracted\")\n",
    "                return None\n",
    "\n",
    "            print(f\"Successfully extracted {len(frames)} frames\")\n",
    "\n",
    "            # Upload frames to S3\n",
    "            for frame_file in frames:\n",
    "                s3_output_key = f\"{frame_images_path}/{video_filename}/{frame_file.name}\"\n",
    "                s3_client.upload_file(str(frame_file), bucket, s3_output_key)\n",
    "\n",
    "            return f\"s3://{bucket}/{frame_images_path}/{video_filename}/\"\n",
    "\n",
    "        except s3_client.exceptions.NoSuchKey:\n",
    "            print(f\"Error: Video file not found in S3: {key}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing video: {str(e)}\")\n",
    "            return None\n",
    "        finally:\n",
    "            # Cleanup\n",
    "            if os.path.exists(local_video_path):\n",
    "                os.remove(local_video_path)\n",
    "            if output_dir.exists():\n",
    "                for file in output_dir.glob(\"*\"):\n",
    "                    file.unlink()\n",
    "                output_dir.rmdir()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {str(e)}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede777dd-4b06-4812-9de6-ae62a330eb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tiled_image(s3_path, font_type):\n",
    "    try:\n",
    "        if not s3_path:\n",
    "            print(\"Invalid S3 path provided\")\n",
    "            return None\n",
    "\n",
    "        # Parse the S3 path\n",
    "        parsed_url = urlparse(s3_path)\n",
    "        bucket_name = parsed_url.netloc\n",
    "        folder_path = parsed_url.path.lstrip('/')\n",
    "        print(\"folder path:\" + folder_path)\n",
    "\n",
    "        s3 = boto3.resource('s3')\n",
    "        bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "        # Get the list of image files\n",
    "        image_keys = [obj.key for obj in bucket.objects.filter(Prefix=folder_path)]\n",
    "        selected_keys = []\n",
    "        for key in image_keys:\n",
    "            if key.endswith(\".jpg\") and \"computed\" not in key:\n",
    "                selected_keys.append(key)\n",
    "\n",
    "        if not selected_keys:\n",
    "            print(\"No frames found to process\")\n",
    "            return None\n",
    "\n",
    "        # Rest of your existing code...\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in create_tiled_image: {e}\")\n",
    "        return None\n",
    "\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28e06ac-3f8d-4b98-8555-7f098a638604",
   "metadata": {},
   "source": [
    "# Test one video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e99d489-88fd-4bee-9e7f-47c6b7ebff49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#frame_images_path = \"extracted-frames\"\n",
    "video_path = \"traffic\"\n",
    "key = \"traffic/TestVideo.mp4\"\n",
    "frame_images_path='frame_images'\n",
    "extracted_frames_path = extract_frames(video_path, key)\n",
    "print(extracted_frames_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f119b1-16f0-47c8-af0b-164e15528d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_grid_path=create_tiled_image(extracted_frames_path, 'DejaVuSans.ttf')\n",
    "print(\"calling LLM \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb9f639-c386-4b0a-8c42-857895b0a821",
   "metadata": {},
   "outputs": [],
   "source": [
    "contextual_summary=get_contextual_summary(image_grid_path,model_id_sonnet35v2)\n",
    "print(\"writing response \")\n",
    "text_data = contextual_summary['content'][0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807f2778-4946-4ee7-99f5-b1b8f218b0be",
   "metadata": {},
   "source": [
    "# Option 2A  Process combined video with Anthropic Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ffe965-4397-4aad-8890-3fa854473abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#frame_images_path = \"extracted-frames\"\n",
    "video_path = \"nova_video\"\n",
    "key = \"nova_video/combined_videos.mov\"\n",
    "frame_images_path='frame_images'\n",
    "extracted_frames_path = extract_frames(video_path, key)\n",
    "print(extracted_frames_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39335d2-d61e-451f-b498-2e7977bfe8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tiled_image1(s3_path, font_type):\n",
    "    MAX_DIMENSION = 8000\n",
    "    \n",
    "    # Parse the S3 path\n",
    "    parsed_url = urlparse(s3_path)\n",
    "    bucket_name = parsed_url.netloc\n",
    "    folder_path = parsed_url.path.lstrip('/')\n",
    "    print(\"folder path:\" + folder_path)\n",
    "\n",
    "    s3 = boto3.resource('s3')\n",
    "    bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "    # Get the list of image files in the S3 folder\n",
    "    image_keys = [obj.key for obj in bucket.objects.filter(Prefix=folder_path)]\n",
    "    selected_keys = []\n",
    "    for key in image_keys:\n",
    "        if key.endswith(\".jpg\") and \"computed\" not in key:\n",
    "            selected_keys.append(key)\n",
    "    \n",
    "    # Sort the image files by frame number\n",
    "    selected_keys.sort(key=lambda x: int(x.split('-')[-1].split('.')[0]))\n",
    "\n",
    "    num_frames = len(selected_keys)\n",
    "    if num_frames == 0:\n",
    "        print(\"No frames found\")\n",
    "        return None\n",
    "\n",
    "    # Load the selected images from S3\n",
    "    images = []\n",
    "    for key in selected_keys:\n",
    "        image_obj = bucket.Object(key).get()\n",
    "        image_data = image_obj['Body'].read()\n",
    "        image = Image.open(BytesIO(image_data))\n",
    "        images.append(image)\n",
    "\n",
    "    # Calculate dimensions for the tiled grid\n",
    "    single_width = images[0].width\n",
    "    single_height = images[0].height\n",
    "    tile_width = single_width * 4\n",
    "    tile_height = single_height * 4 + 50  # Extra height for the black bar\n",
    "\n",
    "    # Check if dimensions exceed maximum allowed size\n",
    "    if tile_width > MAX_DIMENSION or tile_height > MAX_DIMENSION:\n",
    "        # Calculate scaling factor\n",
    "        scale_factor = min(MAX_DIMENSION / tile_width, MAX_DIMENSION / tile_height)\n",
    "        \n",
    "        # Resize all images\n",
    "        new_width = int(single_width * scale_factor)\n",
    "        new_height = int(single_height * scale_factor)\n",
    "        \n",
    "        resized_images = []\n",
    "        for img in images:\n",
    "            resized = img.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "            resized_images.append(resized)\n",
    "        \n",
    "        images = resized_images\n",
    "        tile_width = new_width * 4\n",
    "        tile_height = new_height * 4 + int(50 * scale_factor)  # Scale the black bar height too\n",
    "\n",
    "    # Calculate number of complete grids needed\n",
    "    num_images = (num_frames + 15) // 16  # Round up division\n",
    "    print(\"number of frames: \" + str(num_frames))\n",
    "    print(\"number of image grids: \" + str(num_images))\n",
    "\n",
    "    frame_counter = 0\n",
    "    for k in range(num_images):\n",
    "        # Create a new tiled image for each grid\n",
    "        tiled_image = Image.new('RGB', (tile_width, tile_height))\n",
    "        \n",
    "        for i in range(16):\n",
    "            if frame_counter < num_frames:  # Check if we still have frames to process\n",
    "                row = i // 4\n",
    "                col = i % 4\n",
    "                x = col * images[0].width\n",
    "                y = row * images[0].height + int(50 * scale_factor) if 'scale_factor' in locals() else row * images[0].height + 50\n",
    "                tiled_image.paste(images[frame_counter], (x, y))\n",
    "\n",
    "                # Draw a black bar on top of the image\n",
    "                draw = ImageDraw.Draw(tiled_image)\n",
    "                bar_x = col * images[0].width\n",
    "                bar_y = row * images[0].height\n",
    "                bar_width = images[0].width\n",
    "                bar_height = int(50 * scale_factor) if 'scale_factor' in locals() else 50\n",
    "                draw.rectangle([(bar_x, bar_y), (bar_x + bar_width, bar_y + bar_height)], fill=(0, 0, 0))\n",
    "\n",
    "                # Add frame number in white color on the black bar\n",
    "                font_size = int(50 * scale_factor) if 'scale_factor' in locals() else 50\n",
    "                frame_number = selected_keys[frame_counter].split('-')[-1].split('.')[0]\n",
    "                text_x = bar_x + 10\n",
    "                text_y = bar_y + (bar_height // 2 - font_size // 2)\n",
    "                font = ImageFont.truetype(font_type, font_size)\n",
    "                draw.text((text_x, text_y), frame_number, font=font, fill=(255, 255, 255))\n",
    "                \n",
    "                frame_counter += 1\n",
    "\n",
    "        # Save the tiled image to S3\n",
    "        base_filename = Path(folder_path).stem\n",
    "        grid_filename = f'image_grid-{k}-{base_filename}.jpg'\n",
    "        grid_key = f'{folder_path}computed/{grid_filename}'\n",
    "        grid_path = f'{folder_path}computed'\n",
    "        temp_file = BytesIO()\n",
    "        tiled_image.save(temp_file, format='JPEG')\n",
    "        temp_file.seek(0)\n",
    "        bucket.put_object(Key=grid_key, Body=temp_file)\n",
    "\n",
    "    return f's3://{bucket_name}/{grid_path}/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b98d3b4-df30-4615-bff2-53c3c7a72849",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_grid_path=create_tiled_image1(extracted_frames_path, 'DejaVuSans.ttf')\n",
    "print(\"calling LLM \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6799eb-71fe-4252-b4e5-204c59069937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contextual_summary1(image_grid_path, modelid):\n",
    "    \"\"\"\n",
    "    Invokes Bedrock's conversation API to run a multimodal inference using the input\n",
    "    provided in the request body.\n",
    "    \n",
    "    Args:\n",
    "        image_grid_path: The Amazon S3 uri for the video's image grid (jpeg)\n",
    "        modelid: The Bedrock model ID to use\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize S3 clients\n",
    "    s3 = boto3.resource('s3')\n",
    "    s3_client = boto3.client('s3')\n",
    "    \n",
    "    # Parse S3 path\n",
    "    bucket_name = image_grid_path.split('/')[2]\n",
    "    prefix = '/'.join(image_grid_path.split('/')[3:])\n",
    "    \n",
    "    logger.info(f\"Bucket name: {bucket_name}\")\n",
    "    logger.info(f\"Prefix: {prefix}\")\n",
    "    \n",
    "    # Get bucket\n",
    "    bucket = s3.Bucket(bucket_name)\n",
    "    \n",
    "    # List objects in the folder\n",
    "    try:\n",
    "        image_objects = list(bucket.objects.filter(Prefix=prefix))\n",
    "        logger.info(f\"Found {len(image_objects)} objects with prefix {prefix}\")\n",
    "        \n",
    "        # Filter for image files (assuming jpeg/jpg)\n",
    "        image_keys = [obj.key for obj in image_objects \n",
    "                     if obj.key.lower().endswith(('.jpg', '.jpeg'))]\n",
    "        logger.info(f\"Found {len(image_keys)} image files\")\n",
    "        \n",
    "        if not image_keys:\n",
    "            logger.warning(f\"No image files found in {image_grid_path}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error listing objects in bucket: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "    # Define the analysis prompt\n",
    "    prompt = \"\"\"\n",
    "   As an expert traffic safety analyst, analyze the provided traffic video footage image grid frames showing 3 simultaneous camera angles and:\n",
    "\n",
    "Analyze the provided video footage and answer the following:\n",
    "Are there any pedestrians visible? If yes, describe their location, actions, and appearance.\n",
    "Are any pedestrians at risk due to the driver's behavior? Explain why or why not.\n",
    "Is the driver driving safely? Provide specific examples of unsafe or safe behaviors.\n",
    "Is the driver distracted? If so, describe how and when.\n",
    "    \"\"\"\n",
    "\n",
    "    # Construct the input message\n",
    "    message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": prompt}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Process and add images\n",
    "    if image_keys:\n",
    "        for image_key in image_keys:\n",
    "            try:\n",
    "                logger.info(f\"Processing image: {image_key}\")\n",
    "                \n",
    "                # Get image from S3\n",
    "                response = s3_client.get_object(Bucket=bucket_name, Key=image_key)\n",
    "                image_binary = response['Body'].read()\n",
    "                \n",
    "                # Check image size\n",
    "                image_size = len(image_binary)\n",
    "                logger.info(f\"Image size: {image_size} bytes\")\n",
    "                \n",
    "                # Encode image\n",
    "                base64_string = base64.b64encode(image_binary).decode('utf-8')\n",
    "                logger.info(f\"Successfully encoded image {image_key}\")\n",
    "                \n",
    "                # Add to message\n",
    "                message[\"content\"].append({\n",
    "                    \"type\": \"image\",\n",
    "                    \"source\": {\n",
    "                        \"type\": \"base64\",\n",
    "                        \"media_type\": \"image/jpeg\",\n",
    "                        \"data\": base64_string\n",
    "                    }\n",
    "                })\n",
    "                logger.info(f\"Added image {image_key} to message\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing image {image_key}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "    # Verify images were added\n",
    "    image_count = sum(1 for content in message[\"content\"] if content[\"type\"] == \"image\")\n",
    "    logger.info(f\"Total images added to message: {image_count}\")\n",
    "\n",
    "    # Prepare request body\n",
    "    request_body = {\n",
    "        \"messages\": [message],\n",
    "        \"max_tokens\": 2048,\n",
    "        \"temperature\": 0,\n",
    "        \"top_p\": 0.999,\n",
    "        \"top_k\": 250,\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Initialize Bedrock runtime client\n",
    "        bedrock_runtime = boto3.client('bedrock-runtime')\n",
    "        \n",
    "        logger.info(\"Invoking Bedrock model...\")\n",
    "        \n",
    "        # Invoke model\n",
    "        response = bedrock_runtime.invoke_model(\n",
    "            modelId=modelid,\n",
    "            contentType=\"application/json\",\n",
    "            accept=\"application/json\",\n",
    "            body=json.dumps(request_body)\n",
    "        )\n",
    "        \n",
    "        # Process response\n",
    "        response_body = json.loads(response['body'].read())\n",
    "        input_tokens = response_body[\"usage\"][\"input_tokens\"]\n",
    "        output_tokens = response_body[\"usage\"][\"output_tokens\"]\n",
    "        \n",
    "        logger.info(\"\\nInvocation details:\")\n",
    "        logger.info(f\"Input tokens: {input_tokens}\")\n",
    "        logger.info(f\"Output tokens: {output_tokens}\")\n",
    "        \n",
    "        response_content = response_body.get(\"content\", [])\n",
    "        logger.info(f\"\\nModel responses ({len(response_content)}):\")\n",
    "        for content in response_content:\n",
    "            logger.info(content[\"text\"])\n",
    "            \n",
    "        return response_body\n",
    "\n",
    "    except ClientError as error:\n",
    "        logger.error(\n",
    "            \"Failed to invoke model. Error: %s: %s\",\n",
    "            error.response[\"Error\"][\"Code\"],\n",
    "            error.response[\"Error\"][\"Message\"]\n",
    "        )\n",
    "        raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f8f96b-0803-4c1a-98a0-0758880e3de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "contextual_summary=get_contextual_summary1(image_grid_path,model_id_sonnet35v2)\n",
    "print(\"writing response \")\n",
    "text_data = contextual_summary['content'][0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce907429-cc15-46f6-99c6-f77d7213f0cd",
   "metadata": {},
   "source": [
    "# Option 2B -  Process individual videos's image gride and then summarize each analysis\n",
    "\n",
    "You can use function (dont have test data so dont have the test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c9a11f-0531-4987-8f24-4baf37d6a4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import logging\n",
    "import concurrent.futures\n",
    "import time\n",
    "from datetime import datetime\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def get_contextual_summary(s3_path, modelid):\n",
    "    \"\"\"\n",
    "    Helper function to analyze footage from a single camera view\n",
    "    \n",
    "    Args:\n",
    "        s3_path: Path to the camera footage in S3\n",
    "        modelid: Bedrock model ID to use\n",
    "    \n",
    "    Returns:\n",
    "        Analysis result for the specific camera view\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create the analysis prompt for this camera view\n",
    "        camera_prompt = f\"\"\"\n",
    "        Analyze the driving footage from camera at {s3_path} and provide:\n",
    "        \n",
    "        1. Safety Assessment:\n",
    "           - Vehicle positioning and lane discipline\n",
    "           - Following distance management\n",
    "           - Speed control and consistency\n",
    "           - Response to road conditions and hazards\n",
    "        \n",
    "        2. Risk Identification:\n",
    "           - Immediate safety concerns\n",
    "           - Potential hazards\n",
    "           - Traffic rule compliance\n",
    "        \n",
    "        3. Driver Behavior (if visible):\n",
    "           - Attention level\n",
    "           - Control inputs\n",
    "           - Defensive driving practices\n",
    "        \"\"\"\n",
    "        \n",
    "        # Prepare the message for Bedrock\n",
    "        message = {\n",
    "            \"messages\": [{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [{\"type\": \"text\", \"text\": camera_prompt}]\n",
    "            }],\n",
    "            \"max_tokens\": 1024,\n",
    "            \"temperature\": 0,\n",
    "            \"top_p\": 0.999,\n",
    "            \"top_k\": 250,\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\"\n",
    "        }\n",
    "        \n",
    "        # Call Bedrock with retry logic\n",
    "        max_retries = 3\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                bedrock_runtime = boto3.client('bedrock-runtime')\n",
    "                response = bedrock_runtime.invoke_model(\n",
    "                    modelId=model_id_sonnet35v2,\n",
    "                    contentType=\"application/json\",\n",
    "                    accept=\"application/json\",\n",
    "                    body=json.dumps(message)\n",
    "                )\n",
    "                \n",
    "                return json.loads(response['body'].read())\n",
    "                \n",
    "            except Exception as e:\n",
    "                if attempt == max_retries - 1:\n",
    "                    raise\n",
    "                time.sleep(2 ** attempt)  # Exponential backoff\n",
    "                \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in get_contextual_summary: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def prompt_chaining_safety_analysis(dash_cam_path, rear_cam_path, side_cam_path, modelid):\n",
    "    \"\"\"\n",
    "    Performs a multi-view safety analysis by chaining prompts across different camera angles\n",
    "    and generating a comprehensive final analysis.\n",
    "    \n",
    "    Args:\n",
    "        dash_cam_path: S3 path to front camera footage frames\n",
    "        rear_cam_path: S3 path to rear view camera footage frames\n",
    "        side_cam_path: S3 path to driver-facing camera footage frames\n",
    "        modelid: Bedrock model ID to use\n",
    "    \n",
    "    Returns:\n",
    "        Final comprehensive safety analysis\n",
    "    \"\"\"\n",
    "    logger.info(\"Starting multi-view safety analysis...\")\n",
    "    \n",
    "    # Validate input paths\n",
    "    for path, name in [(dash_cam_path, 'front'), (rear_cam_path, 'rear'), (side_cam_path, 'driver')]:\n",
    "        if not path.startswith('s3://'):\n",
    "            raise ValueError(f\"Invalid S3 path format for {name} camera: {path}\")\n",
    "    \n",
    "    # Store analysis results for each view\n",
    "    view_analyses = {}\n",
    "    \n",
    "    # Process each camera view\n",
    "    camera_views = {\n",
    "        'front_cam': dash_cam_path,\n",
    "        'rear_cam': rear_cam_path,\n",
    "        'driver_cam': side_cam_path\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Process camera views in parallel\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "            future_to_view = {\n",
    "                executor.submit(get_contextual_summary, s3_path, modelid): view_name \n",
    "                for view_name, s3_path in camera_views.items()\n",
    "            }\n",
    "            \n",
    "            for future in concurrent.futures.as_completed(future_to_view):\n",
    "                view_name = future_to_view[future]\n",
    "                try:\n",
    "                    view_result = future.result()\n",
    "                    if view_result and 'content' in view_result:\n",
    "                        view_text = view_result['content'][0]['text']\n",
    "                        view_analyses[view_name] = view_text\n",
    "                        logger.info(f\"Successfully processed {view_name}\")\n",
    "                    else:\n",
    "                        logger.warning(f\"No analysis generated for {view_name}\")\n",
    "                        view_analyses[view_name] = \"Analysis not available\"\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error processing {view_name}: {str(e)}\")\n",
    "                    view_analyses[view_name] = f\"Error in analysis: {str(e)}\"\n",
    "\n",
    "        # Create comprehensive analysis prompt\n",
    "        comprehensive_prompt = f\"\"\"\n",
    "        As a senior traffic safety expert, review the following analyses from multiple camera angles \n",
    "        of the same driving sequence and provide a comprehensive safety assessment.\n",
    "        \n",
    "        FRONT CAMERA ANALYSIS (External View):\n",
    "        {view_analyses.get('front_cam', 'Not available')}\n",
    "        \n",
    "        REAR CAMERA ANALYSIS (External View):\n",
    "        {view_analyses.get('rear_cam', 'Not available')}\n",
    "        \n",
    "        DRIVER CAMERA ANALYSIS (Internal View):\n",
    "        {view_analyses.get('driver_cam', 'Not available')}\n",
    "        \n",
    "        Please provide:\n",
    "        1. Unified Safety Score (1-100):\n",
    "           - Calculate overall safety rating considering all angles\n",
    "           - Break down scoring criteria and weights used\n",
    "           - Factor in driver attention and behavior\n",
    "        \n",
    "        2. Comprehensive Safety Assessment:\n",
    "           - Cross-reference behaviors across camera angles\n",
    "           - Analyze driver attention and responsiveness\n",
    "           - Evaluate external hazard awareness\n",
    "           - Assess compliance with traffic rules\n",
    "        \n",
    "        3. Driver Behavior Analysis:\n",
    "           - Attention level and focus on road\n",
    "           - Response to potential hazards\n",
    "           - Signs of fatigue or distraction\n",
    "           - Use of safety equipment\n",
    "        \n",
    "        4. Critical Safety Recommendations:\n",
    "           - Prioritized improvement areas\n",
    "           - Specific defensive driving techniques\n",
    "           - Driver attention enhancement strategies\n",
    "        \n",
    "        5. Multi-angle Safety Integration:\n",
    "           - Correlation between driver behavior and external events\n",
    "           - Effectiveness of camera coverage\n",
    "           - Suggestions for enhanced monitoring\n",
    "        \"\"\"\n",
    "\n",
    "        # Get final comprehensive analysis with retry logic\n",
    "        max_retries = 3\n",
    "        retry_count = 0\n",
    "        \n",
    "        while retry_count < max_retries:\n",
    "            try:\n",
    "                bedrock_runtime = boto3.client('bedrock-runtime')\n",
    "                final_response = bedrock_runtime.invoke_model(\n",
    "                    modelId=model_id_sonnet37,\n",
    "                    contentType=\"application/json\",\n",
    "                    accept=\"application/json\",\n",
    "                    body=json.dumps({\n",
    "                        \"messages\": [{\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": [{\"type\": \"text\", \"text\": comprehensive_prompt}]\n",
    "                        }],\n",
    "                        \"max_tokens\": 2048,\n",
    "                        \"temperature\": 0,\n",
    "                        \"top_p\": 0.999,\n",
    "                        \"top_k\": 250,\n",
    "                        \"anthropic_version\": \"bedrock-2023-05-31\"\n",
    "                    })\n",
    "                )\n",
    "                \n",
    "                final_result = json.loads(final_response['body'].read())\n",
    "                break\n",
    "                \n",
    "            except Exception as e:\n",
    "                retry_count += 1\n",
    "                if retry_count == max_retries:\n",
    "                    raise Exception(f\"Failed to generate analysis after {max_retries} attempts: {str(e)}\")\n",
    "                logger.warning(f\"Retry {retry_count} of {max_retries} for final analysis\")\n",
    "                time.sleep(2 ** retry_count)  # Exponential backoff\n",
    "\n",
    "        # Process and format the final analysis\n",
    "        if 'content' in final_result:\n",
    "            final_analysis = {\n",
    "                'individual_analyses': view_analyses,\n",
    "                'comprehensive_analysis': final_result['content'][0]['text'],\n",
    "                'metadata': {\n",
    "                    'input_tokens': final_result.get('usage', {}).get('input_tokens', 0),\n",
    "                    'output_tokens': final_result.get('usage', {}).get('output_tokens', 0),\n",
    "                    'timestamp': datetime.now().isoformat(),\n",
    "                    'model_id': modelid\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            logger.info(\"Successfully generated comprehensive safety analysis\")\n",
    "            return final_analysis\n",
    "            \n",
    "        else:\n",
    "            raise Exception(\"No content in final analysis response\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in prompt chaining analysis: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "    finally:\n",
    "        logger.info(\"Completed safety analysis process\")\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434fbe9e-d375-4622-9847-46cce533845d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#frame_images_path = \"extracted-frames\"\n",
    "video_path = \"nova_video\"\n",
    "key = \"nova_video/frontfacing_dc.mov\"\n",
    "frame_images_path='frame_images'\n",
    "extracted_frames_path = extract_frames(video_path, key)\n",
    "print(extracted_frames_path)\n",
    "image_grid_path=create_tiled_image(extracted_frames_path, 'DejaVuSans.ttf')\n",
    "print(\"calling LLM \")\n",
    "contextual_summary=get_contextual_summary(image_grid_path,model_id_sonnet35v2)\n",
    "print(\"writing response \")\n",
    "text_data_front = contextual_summary['content'][0]['text']\n",
    "print(text_data_front)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ac08b1-c771-4dd8-a03b-fb99dc70c44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#frame_images_path = \"extracted-frames\"\n",
    "video_path = \"nova_video\"\n",
    "key = \"nova_video/sidefacing_dc.mov\"\n",
    "frame_images_path='frame_images'\n",
    "extracted_frames_path = extract_frames(video_path, key)\n",
    "print(extracted_frames_path)\n",
    "image_grid_path=create_tiled_image(extracted_frames_path, 'DejaVuSans.ttf')\n",
    "print(\"calling LLM \")\n",
    "contextual_summary=get_contextual_summary(image_grid_path,model_id_sonnet35v2)\n",
    "print(\"writing response \")\n",
    "text_data_side = contextual_summary['content'][0]['text']\n",
    "print(text_data_side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f800042-d187-4819-9daa-39e895f22051",
   "metadata": {},
   "outputs": [],
   "source": [
    "#frame_images_path = \"extracted-frames\"\n",
    "video_path = \"nova_video\"\n",
    "key = \"nova_video/infacing_dc.mov\"\n",
    "frame_images_path='frame_images'\n",
    "extracted_frames_path = extract_frames(video_path, key)\n",
    "print(extracted_frames_path)\n",
    "image_grid_path=create_tiled_image(extracted_frames_path, 'DejaVuSans.ttf')\n",
    "print(\"calling LLM \")\n",
    "contextual_summary=get_contextual_summary(image_grid_path,model_id_sonnet35v2)\n",
    "print(\"writing response \")\n",
    "text_data_infacing = contextual_summary['content'][0]['text']\n",
    "print(text_data_infacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa5e8d3-cf2d-47fb-969b-19e654086d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(client, inface,side,front,model_id,max_tokens=4096, temperature=0, top_p=0.9):\n",
    "    prompt=\"\"\" You are safety expert for safe driving. Analyze the summary from individual camera feed and \n",
    "    generate the final recommendation and summary \n",
    "    <inward_facing_camera>\"\"\"+inface+ \"\"\"</inward_facing_camera> <side_camera>\"\"\"+side+\"\"\" </side_camera> <front_camera>\"\"\"+front+\"\"\"</front_camera>\"\"\"\n",
    "    \n",
    "    response = \"\"\n",
    "    try:\n",
    "        response = bedrock_client.converse(\n",
    "            modelId=model_id_sonnet37,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"text\": prompt\n",
    "                        } \n",
    "                    ]\n",
    "                }\n",
    "                    \n",
    "            ],\n",
    "            inferenceConfig={\n",
    "                \"temperature\": temperature,\n",
    "                \"maxTokens\": max_tokens,\n",
    "                \"topP\": top_p\n",
    "            }\n",
    "            #additionalModelRequestFields={\n",
    "            #}\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        result = \"Model invocation error\"\n",
    "    try:\n",
    "        res=response['output']['message']['content'][0]['text']\n",
    "        result = response['output']['message']['content'][0]['text'] \\\n",
    "        + '\\n--- Latency: ' + str(response['metrics']['latencyMs']) \\\n",
    "        + 'ms - Input tokens:' + str(response['usage']['inputTokens']) \\\n",
    "        + ' - Output tokens:' + str(response['usage']['outputTokens']) + ' ---\\n'\n",
    "        #data=res.split(\":\", 1)\n",
    "        #data.to_csv('file1.csv')\n",
    "        return res\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        result = \"Output parsing error\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6082f6c-9f45-42f5-bb48-08c5f9d2b8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary=summarize(bedrock_client,text_data_infacing,text_data_side,text_data_front,model_id_sonnet37)\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
